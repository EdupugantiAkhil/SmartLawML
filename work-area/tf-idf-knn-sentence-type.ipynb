{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport glob\nimport numpy as np\nimport pandas as pd\nimport csv\nimport string\nimport re\nimport math\nimport sklearn as sk\nimport nltk\nimport heapq\nimport matplotlib.pyplot as plt\nimport pickle\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import svm\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import learning_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T12:47:43.531101Z","iopub.execute_input":"2022-05-08T12:47:43.531407Z","iopub.status.idle":"2022-05-08T12:47:43.595216Z","shell.execute_reply.started":"2022-05-08T12:47:43.531373Z","shell.execute_reply":"2022-05-08T12:47:43.594360Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_files = glob.glob(\"../input/sample1/SmartLawDataset-main/json/*.json\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:43.596814Z","iopub.execute_input":"2022-05-08T12:47:43.597431Z","iopub.status.idle":"2022-05-08T12:47:43.604149Z","shell.execute_reply.started":"2022-05-08T12:47:43.597394Z","shell.execute_reply":"2022-05-08T12:47:43.603267Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"mergejson=pd.DataFrame()\nfor file in train_files:\n    with open(file) as f1: \n        data1 = json.load(f1)\n    df1=pd.DataFrame([data1])\n    mergejson=pd.concat([mergejson,df1])\nmg1=mergejson.drop(['header','background','order','footer','annotationProcessingStage','annotationProcessingStageAnnotations','processedText'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:43.605289Z","iopub.execute_input":"2022-05-08T12:47:43.606034Z","iopub.status.idle":"2022-05-08T12:47:43.825139Z","shell.execute_reply.started":"2022-05-08T12:47:43.605975Z","shell.execute_reply":"2022-05-08T12:47:43.824233Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"header=['ARGUMENT','TYPE']\nfilename = 'final_argument_by.csv'\ndata1=[]\nwith open(filename, 'w') as file:\n    csvwriter = csv.writer(file) # 2. create a csvwriter object\n    csvwriter.writerow(header) # 4. write the header\n    for j in mg1['arguments']:\n        for k in j:           \n            for p in k['argumentSentences']:                \n                data=[]\n                if(p['argumentSentenceType']=='NA'):\n                    continue\n                data.append(p['text'][:])\n                data.append(p['argumentSentenceType'])\n                data1.append(data)\n    csvwriter.writerows(data1) # 5. write the rest of the data\ndataset = pd.read_csv('final_argument_by.csv')\ndf = pd.DataFrame(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:43.827838Z","iopub.execute_input":"2022-05-08T12:47:43.828194Z","iopub.status.idle":"2022-05-08T12:47:43.857435Z","shell.execute_reply.started":"2022-05-08T12:47:43.828148Z","shell.execute_reply":"2022-05-08T12:47:43.856396Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"s =  set(string.punctuation)\ns.add('\\xad')\nfor index, row in df.iterrows():\n    row['ARGUMENT']=row['ARGUMENT'].lower()\n    for x in row['ARGUMENT']:\n        if x in s or re.search(r'-?\\d+', x): \n            row['ARGUMENT']=row['ARGUMENT'].replace(x,\"\").strip()\n#Now we have proper dataset after removing unwanted punctuations etc\narr=[]\narr1=[]\ncount=0\nc1=0\nfor index, row in df.iterrows():\n    arr.append(row['ARGUMENT'])\n    arr1.append(row['TYPE'])\n\ndf1=pd.DataFrame()\ndf1[\"argument\"] = arr\ndf1[\"by\"] = arr1","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:43.858851Z","iopub.execute_input":"2022-05-08T12:47:43.859544Z","iopub.status.idle":"2022-05-08T12:47:44.509881Z","shell.execute_reply.started":"2022-05-08T12:47:43.859508Z","shell.execute_reply":"2022-05-08T12:47:44.509209Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#list of all sentences\nfinal_list=[]\nfor item in df1['argument']:\n    final_list.append(item)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:44.511219Z","iopub.execute_input":"2022-05-08T12:47:44.511640Z","iopub.status.idle":"2022-05-08T12:47:44.517107Z","shell.execute_reply.started":"2022-05-08T12:47:44.511610Z","shell.execute_reply":"2022-05-08T12:47:44.516101Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nvectors = vectorizer.fit_transform(final_list)\nfeature_names = vectorizer.get_feature_names_out()\ndense = vectors.todense()\ndenselist = dense.tolist()\ncolumns=feature_names\nheader=columns\ndf3 = pd.DataFrame(denselist, columns=feature_names) \ndf3['TYpe']=df1['by']","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:44.518416Z","iopub.execute_input":"2022-05-08T12:47:44.518626Z","iopub.status.idle":"2022-05-08T12:47:46.195256Z","shell.execute_reply.started":"2022-05-08T12:47:44.518601Z","shell.execute_reply":"2022-05-08T12:47:46.194294Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y=df3.TYpe\nfeatures=header\nx=df3[features]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:46.196659Z","iopub.execute_input":"2022-05-08T12:47:46.196988Z","iopub.status.idle":"2022-05-08T12:47:46.217903Z","shell.execute_reply.started":"2022-05-08T12:47:46.196898Z","shell.execute_reply":"2022-05-08T12:47:46.217013Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:46.219199Z","iopub.execute_input":"2022-05-08T12:47:46.219561Z","iopub.status.idle":"2022-05-08T12:47:46.265142Z","shell.execute_reply.started":"2022-05-08T12:47:46.219532Z","shell.execute_reply":"2022-05-08T12:47:46.264031Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#KNN model\nknn = KNeighborsClassifier(n_neighbors= 5) # k=3\nknn.fit(X_train,y_train)\nprediction = knn.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:46.267741Z","iopub.execute_input":"2022-05-08T12:47:46.268051Z","iopub.status.idle":"2022-05-08T12:47:46.440762Z","shell.execute_reply.started":"2022-05-08T12:47:46.267966Z","shell.execute_reply":"2022-05-08T12:47:46.439496Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#print(\"{} nÄ±n score: {}\".format(3,knn.score(X_test,y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:46.447428Z","iopub.execute_input":"2022-05-08T12:47:46.450525Z","iopub.status.idle":"2022-05-08T12:47:46.457226Z","shell.execute_reply.started":"2022-05-08T12:47:46.450454Z","shell.execute_reply":"2022-05-08T12:47:46.456237Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"pickle.dump(knn, open('model_knn.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:46.463436Z","iopub.execute_input":"2022-05-08T12:47:46.466770Z","iopub.status.idle":"2022-05-08T12:47:46.539081Z","shell.execute_reply.started":"2022-05-08T12:47:46.466687Z","shell.execute_reply":"2022-05-08T12:47:46.538314Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"pickled_model = pickle.load(open('model_knn.pkl', 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:46.540883Z","iopub.execute_input":"2022-05-08T12:47:46.541126Z","iopub.status.idle":"2022-05-08T12:47:46.576803Z","shell.execute_reply.started":"2022-05-08T12:47:46.541098Z","shell.execute_reply":"2022-05-08T12:47:46.575899Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"s_vect=pickle.dumps(vectorizer)\nfinal_model_vect=pickle.loads(s_vect)\nmodel_file_vect = \"model_vect.pickle\"\nwith open(model_file_vect,'wb') as f:\n    pickle.dump(final_model_vect, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:47:46.577883Z","iopub.execute_input":"2022-05-08T12:47:46.578170Z","iopub.status.idle":"2022-05-08T12:47:46.585785Z","shell.execute_reply.started":"2022-05-08T12:47:46.578140Z","shell.execute_reply":"2022-05-08T12:47:46.585079Z"},"trusted":true},"execution_count":24,"outputs":[]}]}