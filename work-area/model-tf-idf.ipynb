{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport glob\nimport numpy as np\nimport pandas as pd\nimport csv\nimport string\nimport re\nimport math\nimport sklearn as sk\nimport nltk\nimport heapq\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-25T10:58:54.441310Z","iopub.execute_input":"2022-04-25T10:58:54.441635Z","iopub.status.idle":"2022-04-25T10:58:54.447373Z","shell.execute_reply.started":"2022-04-25T10:58:54.441602Z","shell.execute_reply":"2022-04-25T10:58:54.446697Z"},"trusted":true},"execution_count":352,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import learning_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:27.490210Z","iopub.execute_input":"2022-04-25T10:53:27.490813Z","iopub.status.idle":"2022-04-25T10:53:27.678486Z","shell.execute_reply.started":"2022-04-25T10:53:27.490774Z","shell.execute_reply":"2022-04-25T10:53:27.677532Z"},"trusted":true},"execution_count":329,"outputs":[]},{"cell_type":"code","source":"#LOCATE EXACT LOCATION OF ALL JSON FILES IN KAGGLE LOCAL SETUP\ntrain_files = glob.glob(\"../input/part-2/SmartLawDataset-main/json/*.json\")","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:27.679936Z","iopub.execute_input":"2022-04-25T10:53:27.680166Z","iopub.status.idle":"2022-04-25T10:53:27.686338Z","shell.execute_reply.started":"2022-04-25T10:53:27.680137Z","shell.execute_reply":"2022-04-25T10:53:27.685547Z"},"trusted":true},"execution_count":330,"outputs":[]},{"cell_type":"code","source":"#EXTRACT INDIVIDUAL FILES AND GET THEM INTO SINGLE DATAFRAME\ndf_final=pd.DataFrame()\nfor file in train_files:\n    with open(file) as f1: \n        data=json.load(f1) #ALL DATA FROM FILE LOADED INTO DATA\n        df=pd.DataFrame([data]) #CREATE DATAFRAME FOR SINGLE DATA\n        df_final=pd.concat([df_final,df]) #MERGE ALL INDIVIDUAL DATAFRAME INTO SINGLE DATAFRAME\n#MAIN AIM IS TO GENERATE ML ALGO TO DETERMINE ARGUMENT TEXT AND ARGUMENT BY SO REMOVE REST\ndf_final=df_final.drop(['header','background','order','footer','annotationProcessingStage','annotationProcessingStageAnnotations','processedText'],axis=1)\n#AXIS=1 REMOVE COLUMNS","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:27.687278Z","iopub.execute_input":"2022-04-25T10:53:27.688279Z","iopub.status.idle":"2022-04-25T10:53:28.009250Z","shell.execute_reply.started":"2022-04-25T10:53:27.688239Z","shell.execute_reply":"2022-04-25T10:53:28.008027Z"},"trusted":true},"execution_count":331,"outputs":[]},{"cell_type":"code","source":"header=['text','by']\nfilename = 'final_argument_by.csv'\ndata1=[]\nwith open(filename, 'w',encoding=\"UTF-8\") as file:\n    csvwriter = csv.writer(file) # 2. create a csvwriter object\n    csvwriter.writerow(header) # 4. write the header\n    for j in df_final['arguments']:\n        for k in j:\n            data=[]\n            s=k['text'][3:]\n            data.append(s.strip())\n            data.append(k['argumentBy'])\n            data1.append(data)\n    csvwriter.writerows(data1) # 5. write the rest of the data\ndf_final1=pd.read_csv(filename)\n#Use df_final1 dataframe only for further processes and not csv files to ensure encoding is in proper format\nprint(df_final1)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:28.011104Z","iopub.execute_input":"2022-04-25T10:53:28.011830Z","iopub.status.idle":"2022-04-25T10:53:28.051697Z","shell.execute_reply.started":"2022-04-25T10:53:28.011798Z","shell.execute_reply":"2022-04-25T10:53:28.050628Z"},"trusted":true},"execution_count":332,"outputs":[]},{"cell_type":"code","source":"s =  set(string.punctuation)\ns.add('\\xad')\nfor index, row in df_final1.iterrows():\n    for x in row['text']:\n        row['text']=row['text'].lower()\n        if x in s or re.search(r'-?\\d+', x): \n            row['text']=row['text'].replace(x,\"\")\n#Now we have proper dataset after removing unwanted punctuations etc\nbag_of_words=[]\nlos=[]\nfor item in df_final1['text']:\n    los.append(item)\n    for word in item.split():\n        bag_of_words.append(word)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:28.053799Z","iopub.execute_input":"2022-04-25T10:53:28.054147Z","iopub.status.idle":"2022-04-25T10:53:34.206094Z","shell.execute_reply.started":"2022-04-25T10:53:28.054105Z","shell.execute_reply":"2022-04-25T10:53:34.205274Z"},"trusted":true},"execution_count":333,"outputs":[]},{"cell_type":"markdown","source":"Wordset containing all words.\ncreate dic for freq of all words in doc.\ncalculate tf.\n","metadata":{}},{"cell_type":"code","source":"dict_1={}\nfor index,row in df_final1.iterrows():\n    for word in row['text'].split():\n        if word in dict_1:\n            dict_1[word]+=1\n        else:\n            dict_1[word]=1","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:34.207387Z","iopub.execute_input":"2022-04-25T10:53:34.207598Z","iopub.status.idle":"2022-04-25T10:53:34.268577Z","shell.execute_reply.started":"2022-04-25T10:53:34.207567Z","shell.execute_reply":"2022-04-25T10:53:34.267796Z"},"trusted":true},"execution_count":334,"outputs":[]},{"cell_type":"code","source":"def compute_term_frequency(word_dictionary, bag_of_words):\n    term_frequency_dictionary = {}\n    length_of_bag_of_words = len(bag_of_words)\n\n    for word, count in word_dictionary.items():\n        term_frequency_dictionary[word] = count / float(length_of_bag_of_words)\n\n    return term_frequency_dictionary","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:34.269660Z","iopub.execute_input":"2022-04-25T10:53:34.269911Z","iopub.status.idle":"2022-04-25T10:53:34.274614Z","shell.execute_reply.started":"2022-04-25T10:53:34.269881Z","shell.execute_reply":"2022-04-25T10:53:34.274089Z"},"trusted":true},"execution_count":335,"outputs":[]},{"cell_type":"code","source":"dict_2={}\ndict_3={}\nfor item in los:\n    for word in item.split():\n        if word in dict_2 and word not in dict_3:\n            dict_2[word]+=1\n            dict_3[word]=1\n        else:\n            if word not in dict_2:\n                dict_2[word]=1\n                dict_3[word]=1\n    dict_3.clear()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:34.276688Z","iopub.execute_input":"2022-04-25T10:53:34.276933Z","iopub.status.idle":"2022-04-25T10:53:34.320378Z","shell.execute_reply.started":"2022-04-25T10:53:34.276905Z","shell.execute_reply":"2022-04-25T10:53:34.319370Z"},"trusted":true},"execution_count":336,"outputs":[]},{"cell_type":"code","source":"def compute_inverse_document_frequency(full_doc_list):\n    idf_dict = {}\n    length_of_doc_list = len(full_doc_list)\n\n    idf_dict = dict.fromkeys(full_doc_list.keys(), 0)\n    for word, value in idf_dict.items():\n        idf_dict[word] = math.log(length_of_doc_list / (float(value) + 1))\n\n    return idf_dict\n\nfinal_idf_dict = compute_inverse_document_frequency(dict_2)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:34.321636Z","iopub.execute_input":"2022-04-25T10:53:34.321899Z","iopub.status.idle":"2022-04-25T10:53:34.332412Z","shell.execute_reply.started":"2022-04-25T10:53:34.321862Z","shell.execute_reply":"2022-04-25T10:53:34.331701Z"},"trusted":true},"execution_count":337,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nvectors = vectorizer.fit_transform(los)\nfeature_names = vectorizer.get_feature_names_out()\ndense = vectors.todense()\ndenselist = dense.tolist()\ndf_end = pd.DataFrame(denselist, columns=feature_names)\ndf_end['By']=df_final1['by']","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:34.333577Z","iopub.execute_input":"2022-04-25T10:53:34.334172Z","iopub.status.idle":"2022-04-25T10:53:35.072455Z","shell.execute_reply.started":"2022-04-25T10:53:34.334023Z","shell.execute_reply":"2022-04-25T10:53:35.071372Z"},"trusted":true},"execution_count":338,"outputs":[]},{"cell_type":"code","source":"y=df_end.By\nx=df_end[feature_names]\n# Setting up x and y coordinates\n# x.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.073792Z","iopub.execute_input":"2022-04-25T10:53:35.078598Z","iopub.status.idle":"2022-04-25T10:53:35.092567Z","shell.execute_reply.started":"2022-04-25T10:53:35.078525Z","shell.execute_reply":"2022-04-25T10:53:35.091932Z"},"trusted":true},"execution_count":339,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n# check the shape of X_train and X_test\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.094448Z","iopub.execute_input":"2022-04-25T10:53:35.094702Z","iopub.status.idle":"2022-04-25T10:53:35.122284Z","shell.execute_reply.started":"2022-04-25T10:53:35.094673Z","shell.execute_reply":"2022-04-25T10:53:35.121076Z"},"trusted":true},"execution_count":340,"outputs":[]},{"cell_type":"code","source":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.123682Z","iopub.execute_input":"2022-04-25T10:53:35.124130Z","iopub.status.idle":"2022-04-25T10:53:35.195454Z","shell.execute_reply.started":"2022-04-25T10:53:35.124079Z","shell.execute_reply":"2022-04-25T10:53:35.194908Z"},"trusted":true},"execution_count":341,"outputs":[]},{"cell_type":"code","source":"y_pred = gnb.predict(X_test)\ny_pred_train = gnb.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.196333Z","iopub.execute_input":"2022-04-25T10:53:35.196929Z","iopub.status.idle":"2022-04-25T10:53:35.304327Z","shell.execute_reply.started":"2022-04-25T10:53:35.196897Z","shell.execute_reply":"2022-04-25T10:53:35.303381Z"},"trusted":true},"execution_count":342,"outputs":[]},{"cell_type":"code","source":"print('Model accuracy score using TF_IDF- GNB: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.305418Z","iopub.execute_input":"2022-04-25T10:53:35.305628Z","iopub.status.idle":"2022-04-25T10:53:35.312150Z","shell.execute_reply.started":"2022-04-25T10:53:35.305602Z","shell.execute_reply":"2022-04-25T10:53:35.311277Z"},"trusted":true},"execution_count":343,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='linear')\nsvclassifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.313518Z","iopub.execute_input":"2022-04-25T10:53:35.313808Z","iopub.status.idle":"2022-04-25T10:53:35.689426Z","shell.execute_reply.started":"2022-04-25T10:53:35.313768Z","shell.execute_reply":"2022-04-25T10:53:35.688651Z"},"trusted":true},"execution_count":344,"outputs":[]},{"cell_type":"code","source":"y_pred = svclassifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.690624Z","iopub.execute_input":"2022-04-25T10:53:35.691009Z","iopub.status.idle":"2022-04-25T10:53:35.815049Z","shell.execute_reply.started":"2022-04-25T10:53:35.690975Z","shell.execute_reply":"2022-04-25T10:53:35.814221Z"},"trusted":true},"execution_count":345,"outputs":[]},{"cell_type":"code","source":"print('Model accuracy score using TF_IDF- SVC: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.816379Z","iopub.execute_input":"2022-04-25T10:53:35.816685Z","iopub.status.idle":"2022-04-25T10:53:35.822828Z","shell.execute_reply.started":"2022-04-25T10:53:35.816645Z","shell.execute_reply":"2022-04-25T10:53:35.822025Z"},"trusted":true},"execution_count":346,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier  \nclassifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \nclassifier.fit(X_train, y_train)  ","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.824299Z","iopub.execute_input":"2022-04-25T10:53:35.824622Z","iopub.status.idle":"2022-04-25T10:53:35.876266Z","shell.execute_reply.started":"2022-04-25T10:53:35.824571Z","shell.execute_reply":"2022-04-25T10:53:35.875572Z"},"trusted":true},"execution_count":347,"outputs":[]},{"cell_type":"code","source":"y_pred= classifier.predict(X_test) ","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.879071Z","iopub.execute_input":"2022-04-25T10:53:35.879600Z","iopub.status.idle":"2022-04-25T10:53:35.945888Z","shell.execute_reply.started":"2022-04-25T10:53:35.879567Z","shell.execute_reply":"2022-04-25T10:53:35.944887Z"},"trusted":true},"execution_count":348,"outputs":[]},{"cell_type":"code","source":"print('Model accuracy score using TF_IDF- KNN: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.947974Z","iopub.execute_input":"2022-04-25T10:53:35.948659Z","iopub.status.idle":"2022-04-25T10:53:35.955363Z","shell.execute_reply.started":"2022-04-25T10:53:35.948609Z","shell.execute_reply":"2022-04-25T10:53:35.954438Z"},"trusted":true},"execution_count":349,"outputs":[]},{"cell_type":"code","source":"def learn_curve(X,y,c):\n    le = preprocessing.LabelEncoder() # Label encoding the target\n    sc = preprocessing.StandardScaler() # Scaling the input features\n    y = le.fit_transform(y)#Label Encoding the target\n    log_reg = LogisticRegression(max_iter=200,random_state=11,C=c)\n    lr = Pipeline(steps=(['scaler',sc],\n                        ['classifier',log_reg]))\n    \n    \n    cv = StratifiedKFold(n_splits=5,random_state=11,shuffle=True) # Creating a StratifiedKFold object with 5 folds\n    cv_scores = cross_val_score(lr,X,y,scoring=\"accuracy\",cv=cv) # Storing the CV scores (accuracy) of each fold\n    lr.fit(X,y) # Fitting the model\n    train_score = lr.score(X,y) # Scoring the model on train set\n    #Building the learning curve\n    train_size,train_scores,test_scores = learning_curve(estimator=lr,X=X,y=y,cv=cv,scoring=\"accuracy\",random_state=11)\n    train_scores = 1-np.mean(train_scores,axis=1)#converting the accuracy score to misclassification rate\n    test_scores = 1-np.mean(test_scores,axis=1)#converting the accuracy score to misclassification rate\n    lc = pd.DataFrame({\"Training_size\":train_size,\"Training_loss\":train_scores,\"Validation_loss\":test_scores}).melt(id_vars=\"Training_size\")\n    return {\"cv_scores\":cv_scores,\n           \"train_score\":train_score,\n           \"learning_curve\":lc}","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:53:35.957023Z","iopub.execute_input":"2022-04-25T10:53:35.957481Z","iopub.status.idle":"2022-04-25T10:53:35.974423Z","shell.execute_reply.started":"2022-04-25T10:53:35.957434Z","shell.execute_reply":"2022-04-25T10:53:35.973579Z"},"trusted":true},"execution_count":350,"outputs":[]},{"cell_type":"code","source":"lc = learn_curve(x,y,1)\nprint(f'Cross Validation Accuracies:\\n{\"-\"*25}\\n{list(lc[\"cv_scores\"])}\\n\\n\\\nMean Cross Validation Accuracy:\\n{\"-\"*25}\\n{np.mean(lc[\"cv_scores\"])}\\n\\n\\\nStandard Deviation of Cross Validation Accuracy:\\n{\"-\"*25}\\n{np.std(lc[\"cv_scores\"])}\\n\\n\\\nTraining Accuracy:\\n{\"-\"*15}\\n{lc[\"train_score\"]}\\n\\n')\nsns.lineplot(data=lc[\"learning_curve\"],x=\"Training_size\",y=\"value\",hue=\"variable\")\nplt.title(\"Learning Curve of Model\")\nplt.ylabel(\"Misclassification Rate/Loss\");","metadata":{"execution":{"iopub.status.busy":"2022-04-25T10:59:03.591692Z","iopub.execute_input":"2022-04-25T10:59:03.592005Z","iopub.status.idle":"2022-04-25T10:59:32.777696Z","shell.execute_reply.started":"2022-04-25T10:59:03.591973Z","shell.execute_reply":"2022-04-25T10:59:32.776592Z"},"trusted":true},"execution_count":353,"outputs":[]}]}