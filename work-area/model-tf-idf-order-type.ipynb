{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport glob\nimport numpy as np\nimport pandas as pd\nimport csv\nimport string\nimport re\nimport math\nimport sklearn as sk\nimport nltk\nimport heapq\nimport matplotlib.pyplot as plt\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T13:39:06.997886Z","iopub.execute_input":"2022-05-08T13:39:06.998289Z","iopub.status.idle":"2022-05-08T13:39:07.002773Z","shell.execute_reply.started":"2022-05-08T13:39:06.998258Z","shell.execute_reply":"2022-05-08T13:39:07.00201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn import svm\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import learning_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:39:12.864613Z","iopub.execute_input":"2022-05-08T13:39:12.865199Z","iopub.status.idle":"2022-05-08T13:39:12.872652Z","shell.execute_reply.started":"2022-05-08T13:39:12.865165Z","shell.execute_reply":"2022-05-08T13:39:12.871305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LOCATE EXACT LOCATION OF ALL JSON FILES IN KAGGLE LOCAL SETUP\ntrain_files = glob.glob(\"../input/ordertype/SmartLawDataset-main/json/*.json\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:39:15.91351Z","iopub.execute_input":"2022-05-08T13:39:15.913855Z","iopub.status.idle":"2022-05-08T13:39:15.92318Z","shell.execute_reply.started":"2022-05-08T13:39:15.913821Z","shell.execute_reply":"2022-05-08T13:39:15.922446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EXTRACT INDIVIDUAL FILES AND GET THEM INTO SINGLE DATAFRAME\ndf_final=pd.DataFrame()\nfor file in train_files:\n    with open(file) as f1: \n        data=json.load(f1) #ALL DATA FROM FILE LOADED INTO DATA\n        df=pd.DataFrame([data]) #CREATE DATAFRAME FOR SINGLE DATA\n        df_final=pd.concat([df_final,df]) #MERGE ALL INDIVIDUAL DATAFRAME INTO SINGLE DATAFRAME\n#MAIN AIM IS TO GENERATE ML ALGO TO DETERMINE ARGUMENT TEXT AND ARGUMENT BY SO REMOVE REST\n#df_final=df_final.drop(['header','background','order','footer','annotationProcessingStage','annotationProcessingStageAnnotations','processedText'],axis=1)\n#AXIS=1 REMOVE COLUMNS","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:39:18.332582Z","iopub.execute_input":"2022-05-08T13:39:18.333505Z","iopub.status.idle":"2022-05-08T13:39:18.672904Z","shell.execute_reply.started":"2022-05-08T13:39:18.333446Z","shell.execute_reply":"2022-05-08T13:39:18.67212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final=df_final.drop(['header','background','arguments','footer','annotationProcessingStage','annotationProcessingStageAnnotations','processedText'],axis=1)\ndf_final.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:39:21.874531Z","iopub.execute_input":"2022-05-08T13:39:21.875318Z","iopub.status.idle":"2022-05-08T13:39:21.92121Z","shell.execute_reply.started":"2022-05-08T13:39:21.875276Z","shell.execute_reply":"2022-05-08T13:39:21.920317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"header=['text','orderType']\nfilename = 'final_argument_by.csv'\ndata1=[]\nwith open(filename, 'w',encoding=\"UTF-8\") as file:\n    csvwriter = csv.writer(file) # 2. create a csvwriter object\n    csvwriter.writerow(header) # 4. write the header\n    for j in df_final['order']:\n        data=[]\n        s=j['text']\n        data.append(s.strip())\n        data.append(j['orderType'])\n        data1.append(data)\n    csvwriter.writerows(data1) # 5. write the rest of the data\ndf_final1=pd.read_csv(filename)\n#Use df_final1 dataframe only for further processes and not csv files to ensure encoding is in proper format\nprint(df_final1)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:39:28.841583Z","iopub.execute_input":"2022-05-08T13:39:28.842472Z","iopub.status.idle":"2022-05-08T13:39:28.865436Z","shell.execute_reply.started":"2022-05-08T13:39:28.842422Z","shell.execute_reply":"2022-05-08T13:39:28.864376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final1.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:39:32.894888Z","iopub.execute_input":"2022-05-08T13:39:32.895197Z","iopub.status.idle":"2022-05-08T13:39:32.906268Z","shell.execute_reply.started":"2022-05-08T13:39:32.895166Z","shell.execute_reply":"2022-05-08T13:39:32.905193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s =  set(string.punctuation)\ns.add('\\xad')\nfor index, row in df_final1.iterrows():\n    print(row['text'])\n    for x in row['text']:\n        row['text']=row['text'].lower()\n        if x in s or re.search(r'-?\\d+', x): \n            row['text']=row['text'].replace(x,\"\")\n#Now we have proper dataset after removing unwanted punctuations etc\nbag_of_words=[]\nlos=[]\nfor item in df_final1['text']:\n    los.append(item)\n    for word in item.split():\n        bag_of_words.append(word)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:41:21.587024Z","iopub.execute_input":"2022-05-08T13:41:21.587906Z","iopub.status.idle":"2022-05-08T13:41:23.034979Z","shell.execute_reply.started":"2022-05-08T13:41:21.587857Z","shell.execute_reply":"2022-05-08T13:41:23.033602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wordset containing all words.\ncreate dic for freq of all words in doc.\ncalculate tf.\n","metadata":{}},{"cell_type":"code","source":"dict_1={}\nfor index,row in df_final1.iterrows():\n    for word in row['text'].split():\n        if word in dict_1:\n            dict_1[word]+=1\n        else:\n            dict_1[word]=1","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:41:53.715168Z","iopub.execute_input":"2022-05-08T13:41:53.716399Z","iopub.status.idle":"2022-05-08T13:41:53.734939Z","shell.execute_reply.started":"2022-05-08T13:41:53.716341Z","shell.execute_reply":"2022-05-08T13:41:53.733816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_term_frequency(word_dictionary, bag_of_words):\n    term_frequency_dictionary = {}\n    length_of_bag_of_words = len(bag_of_words)\n\n    for word, count in word_dictionary.items():\n        term_frequency_dictionary[word] = count / float(length_of_bag_of_words)\n\n    return term_frequency_dictionary","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:41:58.808181Z","iopub.execute_input":"2022-05-08T13:41:58.808563Z","iopub.status.idle":"2022-05-08T13:41:58.814199Z","shell.execute_reply.started":"2022-05-08T13:41:58.808514Z","shell.execute_reply":"2022-05-08T13:41:58.813085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_2={}\ndict_3={}\nfor item in los:\n    for word in item.split():\n        if word in dict_2 and word not in dict_3:\n            dict_2[word]+=1\n            dict_3[word]=1\n        else:\n            if word not in dict_2:\n                dict_2[word]=1\n                dict_3[word]=1\n    dict_3.clear()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:42:03.378574Z","iopub.execute_input":"2022-05-08T13:42:03.378961Z","iopub.status.idle":"2022-05-08T13:42:03.39472Z","shell.execute_reply.started":"2022-05-08T13:42:03.378924Z","shell.execute_reply":"2022-05-08T13:42:03.393609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_inverse_document_frequency(full_doc_list):\n    idf_dict = {}\n    length_of_doc_list = len(full_doc_list)\n\n    idf_dict = dict.fromkeys(full_doc_list.keys(), 0)\n    for word, value in idf_dict.items():\n        idf_dict[word] = math.log(length_of_doc_list / (float(value) + 1))\n\n    return idf_dict\n\nfinal_idf_dict = compute_inverse_document_frequency(dict_2)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:42:06.271859Z","iopub.execute_input":"2022-05-08T13:42:06.272478Z","iopub.status.idle":"2022-05-08T13:42:06.279383Z","shell.execute_reply.started":"2022-05-08T13:42:06.272439Z","shell.execute_reply":"2022-05-08T13:42:06.278675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nvectors = vectorizer.fit_transform(los)\nfeature_names = vectorizer.get_feature_names_out()\ndense = vectors.todense()\ndenselist = dense.tolist()\ndf_end = pd.DataFrame(denselist, columns=feature_names)\ndf_end['orderType']=df_final1['orderType']","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:42:25.826831Z","iopub.execute_input":"2022-05-08T13:42:25.827141Z","iopub.status.idle":"2022-05-08T13:42:25.911266Z","shell.execute_reply.started":"2022-05-08T13:42:25.827112Z","shell.execute_reply":"2022-05-08T13:42:25.910164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=df_end.orderType\nx=df_end[feature_names]\n# Setting up x and y coordinates\n# x.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:42:38.800577Z","iopub.execute_input":"2022-05-08T13:42:38.801792Z","iopub.status.idle":"2022-05-08T13:42:38.811108Z","shell.execute_reply.started":"2022-05-08T13:42:38.801715Z","shell.execute_reply":"2022-05-08T13:42:38.810342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n# check the shape of X_train and X_test\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:42:41.981491Z","iopub.execute_input":"2022-05-08T13:42:41.982403Z","iopub.status.idle":"2022-05-08T13:42:41.992275Z","shell.execute_reply.started":"2022-05-08T13:42:41.982362Z","shell.execute_reply":"2022-05-08T13:42:41.991694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:42:45.366339Z","iopub.execute_input":"2022-05-08T13:42:45.36704Z","iopub.status.idle":"2022-05-08T13:42:45.389614Z","shell.execute_reply.started":"2022-05-08T13:42:45.366988Z","shell.execute_reply":"2022-05-08T13:42:45.388713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = gnb.predict(X_test)\ny_pred_train = gnb.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:42:49.704912Z","iopub.execute_input":"2022-05-08T13:42:49.705584Z","iopub.status.idle":"2022-05-08T13:42:49.734884Z","shell.execute_reply.started":"2022-05-08T13:42:49.705532Z","shell.execute_reply":"2022-05-08T13:42:49.734084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Model accuracy score using TF_IDF- GNB: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:42:54.768087Z","iopub.execute_input":"2022-05-08T13:42:54.768718Z","iopub.status.idle":"2022-05-08T13:42:54.775847Z","shell.execute_reply.started":"2022-05-08T13:42:54.768668Z","shell.execute_reply":"2022-05-08T13:42:54.77472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='linear')\nsvclassifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:43:05.066264Z","iopub.execute_input":"2022-05-08T13:43:05.067264Z","iopub.status.idle":"2022-05-08T13:43:05.085405Z","shell.execute_reply.started":"2022-05-08T13:43:05.067213Z","shell.execute_reply":"2022-05-08T13:43:05.084805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = svclassifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:43:08.5691Z","iopub.execute_input":"2022-05-08T13:43:08.569884Z","iopub.status.idle":"2022-05-08T13:43:08.583503Z","shell.execute_reply.started":"2022-05-08T13:43:08.569843Z","shell.execute_reply":"2022-05-08T13:43:08.582865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Model accuracy score using TF_IDF- SVC: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:43:11.907024Z","iopub.execute_input":"2022-05-08T13:43:11.907296Z","iopub.status.idle":"2022-05-08T13:43:11.914776Z","shell.execute_reply.started":"2022-05-08T13:43:11.907269Z","shell.execute_reply":"2022-05-08T13:43:11.913605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier  \nclassifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \nclassifier.fit(X_train, y_train)  ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:43:25.356652Z","iopub.execute_input":"2022-05-08T13:43:25.35727Z","iopub.status.idle":"2022-05-08T13:43:25.431594Z","shell.execute_reply.started":"2022-05-08T13:43:25.357222Z","shell.execute_reply":"2022-05-08T13:43:25.430614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred= classifier.predict(X_test) ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:43:31.705087Z","iopub.execute_input":"2022-05-08T13:43:31.705423Z","iopub.status.idle":"2022-05-08T13:43:31.728853Z","shell.execute_reply.started":"2022-05-08T13:43:31.705389Z","shell.execute_reply":"2022-05-08T13:43:31.727678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Model accuracy score using TF_IDF- KNN: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:43:34.78118Z","iopub.execute_input":"2022-05-08T13:43:34.781512Z","iopub.status.idle":"2022-05-08T13:43:34.78922Z","shell.execute_reply.started":"2022-05-08T13:43:34.781478Z","shell.execute_reply":"2022-05-08T13:43:34.788001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def learn_curve(X,y,c):\n    le = preprocessing.LabelEncoder() # Label encoding the target\n    sc = preprocessing.StandardScaler() # Scaling the input features\n    y = le.fit_transform(y)#Label Encoding the target\n    log_reg = LogisticRegression(max_iter=200,random_state=11,C=c)\n    lr = Pipeline(steps=(['scaler',sc],\n                        ['classifier',log_reg]))\n    \n    \n    cv = StratifiedKFold(n_splits=5,random_state=11,shuffle=True) # Creating a StratifiedKFold object with 5 folds\n    cv_scores = cross_val_score(lr,X,y,scoring=\"accuracy\",cv=cv) # Storing the CV scores (accuracy) of each fold\n    lr.fit(X,y) # Fitting the model\n    train_score = lr.score(X,y) # Scoring the model on train set\n    #Building the learning curve\n    train_size,train_scores,test_scores = learning_curve(estimator=lr,X=X,y=y,cv=cv,scoring=\"accuracy\",random_state=11)\n    train_scores = 1-np.mean(train_scores,axis=1)#converting the accuracy score to misclassification rate\n    test_scores = 1-np.mean(test_scores,axis=1)#converting the accuracy score to misclassification rate\n    lc = pd.DataFrame({\"Training_size\":train_size,\"Training_loss\":train_scores,\"Validation_loss\":test_scores}).melt(id_vars=\"Training_size\")\n    return {\"cv_scores\":cv_scores,\n           \"train_score\":train_score,\n           \"learning_curve\":lc}","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:43:44.042849Z","iopub.execute_input":"2022-05-08T13:43:44.043151Z","iopub.status.idle":"2022-05-08T13:43:44.053294Z","shell.execute_reply.started":"2022-05-08T13:43:44.043116Z","shell.execute_reply":"2022-05-08T13:43:44.052257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lc = learn_curve(x,y,1)\nprint(f'Cross Validation Accuracies:\\n{\"-\"*25}\\n{list(lc[\"cv_scores\"])}\\n\\n\\\nMean Cross Validation Accuracy:\\n{\"-\"*25}\\n{np.mean(lc[\"cv_scores\"])}\\n\\n\\\nStandard Deviation of Cross Validation Accuracy:\\n{\"-\"*25}\\n{np.std(lc[\"cv_scores\"])}\\n\\n\\\nTraining Accuracy:\\n{\"-\"*15}\\n{lc[\"train_score\"]}\\n\\n')\nsns.lineplot(data=lc[\"learning_curve\"],x=\"Training_size\",y=\"value\",hue=\"variable\")\nplt.title(\"Learning Curve of Model\")\nplt.ylabel(\"Misclassification Rate/Loss\");","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:44:13.281815Z","iopub.execute_input":"2022-05-08T13:44:13.28254Z","iopub.status.idle":"2022-05-08T13:44:16.301469Z","shell.execute_reply.started":"2022-05-08T13:44:13.282491Z","shell.execute_reply":"2022-05-08T13:44:16.300456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVMtrained=svm.SVC()\nSVMtrained.fit(x.values,y)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:02:00.732389Z","iopub.execute_input":"2022-05-08T14:02:00.732705Z","iopub.status.idle":"2022-05-08T14:02:00.745204Z","shell.execute_reply.started":"2022-05-08T14:02:00.732674Z","shell.execute_reply":"2022-05-08T14:02:00.744323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNNtrained= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \nKNNtrained.fit(x.values,y) ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:02:03.296977Z","iopub.execute_input":"2022-05-08T14:02:03.297605Z","iopub.status.idle":"2022-05-08T14:02:03.307385Z","shell.execute_reply.started":"2022-05-08T14:02:03.297555Z","shell.execute_reply":"2022-05-08T14:02:03.306689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GNBtrained = GaussianNB()\nGNBtrained.fit(x.values,y)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:04:02.922369Z","iopub.execute_input":"2022-05-08T14:04:02.922693Z","iopub.status.idle":"2022-05-08T14:04:02.93393Z","shell.execute_reply.started":"2022-05-08T14:04:02.922662Z","shell.execute_reply":"2022-05-08T14:04:02.932723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_file = \"SVM_type\"\nwith open(model_file,'wb') as f:\n    pickle.dump(SVMtrained, f)\n\n    \nmodel_file = \"KNN_type\"\nwith open(model_file,'wb') as f:\n    pickle.dump(KNNtrained, f)\n\n\nmodel_file = \"GNB_type\"\nwith open(model_file,'wb') as f:\n    pickle.dump(GNBtrained, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:04:05.143435Z","iopub.execute_input":"2022-05-08T14:04:05.143798Z","iopub.status.idle":"2022-05-08T14:04:05.154355Z","shell.execute_reply.started":"2022-05-08T14:04:05.143761Z","shell.execute_reply":"2022-05-08T14:04:05.153462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_file=\"model_type_vect\"\nwith open(model_file,'wb') as f:\n    pickle.dump(vectorizer, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:04:38.176822Z","iopub.execute_input":"2022-05-08T14:04:38.178103Z","iopub.status.idle":"2022-05-08T14:04:38.184468Z","shell.execute_reply.started":"2022-05-08T14:04:38.178025Z","shell.execute_reply":"2022-05-08T14:04:38.18322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model_vect = pickle.load(open(\"model_vect\", 'rb'))\nX_vec=loaded_model_vect.transform([\"heard learned advocate mr waghmare for the applicant\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model_argby = pickle.load(open(\"model_arg_by\", 'rb'))\nprint(loaded_model_argby.predict(X_vec.toarray()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}